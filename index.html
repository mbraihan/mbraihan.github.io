<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="googleea3a5d907402b63b.html"> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Mohammad Raihanul Bashar </title> <meta name="author" content="Mohammad Raihanul Bashar"> <meta name="description" content="PhD student exploring on how to improve interaction techniques within XR using HCI framework and AI."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website, raihan, mohammad raihanul bashar"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?4ee140d0c7b1d5ca6cc5692caaf6bfdd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mbraihan.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">Home <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Mohammad Raihanul</span> Bashar </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 1000px) 291.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?c2d10cc2ab450d98560c8c6c041581ed" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p> H-964, ER Building </p> <p> Concordia University </p> <p> 2155 Guy St, Montreal, H3H 2L9 </p> </div> </div> <div class="clearfix"> <p>I am a Ph.D. candidate in the <a href="https://users.encs.concordia.ca/~abatmaz/" rel="external nofollow noopener" target="_blank">EXiT Lab</a> at Concordia University, advised by <a href="https://users.encs.concordia.ca/~abatmaz/about.html" rel="external nofollow noopener" target="_blank">Dr. Anil Ufuk Batmaz</a>.</p> <p>My research centers on Virtual Reality, Augmented Reality and 3D User Interfaces, focusing on improving user interaction and experience in virtual environments. By integrating methodologies from human-computer interaction (HCI) and immersive technologies, I design, develop, and evaluate interactive VR systems that improve human capabilities in creating, consuming, and interacting with digital content, including video, audio, images, and graphical user interfaces.</p> <p>Previously, I worked as a Senior Engineer (MLOps) at <a href="https://www.quantigo.ai/" rel="external nofollow noopener" target="_blank">Quantigo AI</a>, where I led a team of four engineer. Before that, I worked as a AI Engineer at <a href="https://www.opus-bd.com/" rel="external nofollow noopener" target="_blank">Opus Technolgoy Limited</a> and trained an intelligent agent for CS: GO using offline RL technique.</p> <p>I received my bachelor’s degree in Computer Science, at Independent University, Bangladesh in 2017. At IUB, I used to work on machine learning, deep leraning, reinforcement learning with <a href="http://www.cse.iub.edu.bd/faculties/25" rel="external nofollow noopener" target="_blank">Prof. M. Ashraful Amin</a> &amp; <a href="http://www.cse.iub.edu.bd/faculties/53" rel="external nofollow noopener" target="_blank">Dr. Amin Ahsan Ali</a> at <a href="https://ccds.ai" rel="external nofollow noopener" target="_blank">CCDS</a>.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Apr 15, 2025</th> <td> Woohoo! Successfully defended my PhD proposal and Admitted to Candidacy. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 21, 2025</th> <td> One <a href="https://www.linkedin.com/posts/wolfgang-stuerzlinger-87a48030b_there-is-more-to-dwell-than-meets-the-eye-activity-7320579925592195090-IsA5?utm_source=social_share_send&amp;utm_medium=member_desktop_web&amp;rcm=ACoAABHVBxABoGyOGeK9AER2VZ6K7HEIyFIrDC8" rel="external nofollow noopener" target="_blank">paper</a> accepted at <a href="https://chi2025.acm.org/" rel="external nofollow noopener" target="_blank">ACM CHI EA 2025</a> the premier international conference of Human-Computer Interaction. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 16, 2025</th> <td> One <a href="https://www.linkedin.com/posts/wolfgang-stuerzlinger-87a48030b_there-is-more-to-dwell-than-meets-the-eye-activity-7285904649163825152-fl1k?utm_source=social_share_sheet&amp;utm_medium=member_desktop_web" rel="external nofollow noopener" target="_blank">paper</a> accepted at <a href="https://chi2025.acm.org/" rel="external nofollow noopener" target="_blank">ACM CHI 2025</a> the premier international conference of Human-Computer Interaction. </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 11, 2024</th> <td> One paper accepted for the <a href="https://www.computer.org/csdl/journal/tg" rel="external nofollow noopener" target="_blank">IEEE TVCG Journal</a> at <a href="https://ieeevr.org/2025/" rel="external nofollow noopener" target="_blank">IEEE VR ‘25</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 24, 2024</th> <td> Excited to announce that I will be starting my Mitacs Accelerate internship this fall. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/VAC_Model.gif" sizes="200px"> <img src="/assets/img/publication_preview/VAC_Model.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="VAC_Model.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="bashar2025depthvac" class="col-sm-8"> <div class="title">The Effect of Visual Depth on the Vergence-Accommodation Conflict on 3D Selection Performance within Virtual Reality Headsets</div> <div class="author"> <em>Mohammad Raihanul Bashar</em>, <a href="https://www.mayradonaji.net/" rel="external nofollow noopener" target="_blank">Mayra Donaji Barrera Machuca</a>, <a href="https://vvise.iat.sfu.ca/people/wolfgang-stuerzlinger" rel="external nofollow noopener" target="_blank">Wolfgang Stuerzlinger</a>, and <a href="https://users.encs.concordia.ca/~abatmaz" rel="external nofollow noopener" target="_blank">Anil Ufuk Batmaz</a> </div> <div class="periodical"> <em>Visual Computer</em>, May 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1007/s00371-025-03990-x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/article/10.1007/s00371-025-03990-x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="https://doi.org/10.1007/s00371-025-03990-x" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=zDyfhn0AAAAJ&amp;citation_for_view=zDyfhn0AAAAJ:0EnyYjriUFMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Prior studies have shown that the vergence–accommodation conflict negatively affects the interaction performance in virtual reality (VR) and augmented reality (AR) systems, particularly as object depth increases. This paper examines user selection performance across six different visual depths. Through a study closely resembling prior research, eighteen participants participated in an ISO 9241:411 task with six different depth distances. We observed that with higher depth values, selection times increased, while the throughput performance of the participants decreased. Based on this finding, we propose a Fitts’ law model based on the focal distances, which models pointing times in VR and AR systems with substantially higher accuracy. We hope that our findings aid developers in creating 3D user interfaces for VR and AR that offer better performance and an improved user experience.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bashar2025depthvac</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Effect of Visual Depth on the Vergence-Accommodation Conflict on 3D Selection Performance within Virtual Reality Headsets}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bashar, Mohammad Raihanul and Barrera Machuca, Mayra Donaji and Stuerzlinger, Wolfgang and Batmaz, Anil Ufuk}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Visual Computer}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Virtual Reality, Vergence-Accommodation Conflict, Stereo Deficiencies, Distal Pointing, Ray Casting, Selection, Fitts’ Law}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1432-2315}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s00371-025-03990-x}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/CHI_dwell.gif" sizes="200px"> <img src="/assets/img/publication_preview/CHI_dwell.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CHI_dwell.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="10.1145/3706598.3713781" class="col-sm-8"> <div class="title">There Is More to Dwell Than Meets the Eye: Toward Better Gaze-Based Text Entry Systems With Multi-Threshold Dwell</div> <div class="author"> <a href="https://scholar.google.com/citations?user=1Nt5UowAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Aunnoy K Mutasim</a>, <em>Mohammad Raihanul Bashar</em>, <a href="https://people.bath.ac.uk/cl2073/" rel="external nofollow noopener" target="_blank">Christof Lutteroth</a>, <a href="https://users.encs.concordia.ca/~abatmaz" rel="external nofollow noopener" target="_blank">Anil Ufuk Batmaz</a>, and <a href="https://vvise.iat.sfu.ca/people/wolfgang-stuerzlinger" rel="external nofollow noopener" target="_blank">Wolfgang Stuerzlinger</a> </div> <div class="periodical"> <em>In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems</em>, Yokohama, Tokyo, Japan, May 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3706598.3713781" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/full/10.1145/3706598.3713781" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1145/3706598.3713781" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=zDyfhn0AAAAJ&amp;citation_for_view=zDyfhn0AAAAJ:roLk4NBRz8UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-3-4285F4?logo=googlescholar&amp;labelColor=beige" alt="3 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Dwell-based text entry seems to peak at 20 words per minute (WPM). Yet, little is known about the factors contributing to this limit, except that it requires extensive training. Thus, we conducted a longitudinal study, broke the overall dwell-based selection time into six different components, and identified several design challenges and opportunities. Subsequently, we designed two novel dwell keyboards that use multiple yet much shorter dwell thresholds: Dual-Threshold Dwell (DTD) and Multi-Threshold Dwell (MTD). The performance analysis showed that MTD (18.3 WPM) outperformed both DTD (15.3 WPM) and the conventional Constant-Threshold Dwell (12.9 WPM). Notably, absolute novices achieved these speeds within just 30 phrases. Moreover, MTD’s performance is also the fastest-ever reported average text entry speed for gaze-based keyboards. Finally, we discuss how our chosen parameters can be further optimized to pave the way toward more efficient dwell-based text entry.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3706598.3713781</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mutasim, Aunnoy K and Bashar, Mohammad Raihanul and Lutteroth, Christof and Batmaz, Anil Ufuk and Stuerzlinger, Wolfgang}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{There Is More to Dwell Than Meets the Eye: Toward Better Gaze-Based Text Entry Systems With Multi-Threshold Dwell}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400713941}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3706598.3713781}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3706598.3713781}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{1088}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Text Entry, Eye Gaze, Eye-Tracking, Dwell Thresholds, Learnability, QWERTY}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Yokohama, Tokyo, Japan}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '25}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/CHI_depth3DSketch.gif" sizes="200px"> <img src="/assets/img/publication_preview/CHI_depth3DSketch.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CHI_depth3DSketch.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="10.1145/3706599.3719717" class="col-sm-8"> <div class="title">Depth3DSketch: Freehand Sketching Out of Arm’s Reach in Virtual Reality</div> <div class="author"> <em>Mohammad Raihanul Bashar</em>, Mohammadreza Amini, <a href="https://vvise.iat.sfu.ca/people/wolfgang-stuerzlinger" rel="external nofollow noopener" target="_blank">Wolfgang Stuerzlinger</a>, <a href="https://scholar.google.com.tr/citations?user=0J1AIrkAAAAJ&amp;hl=tr" rel="external nofollow noopener" target="_blank">Mine Sarac</a>, <a href="https://kenpfeuffer.com/" rel="external nofollow noopener" target="_blank">Ken Pfeuffer</a>, <a href="https://www.mayradonaji.net/" rel="external nofollow noopener" target="_blank">Mayra Donaji Barrera Machuca</a>, and <a href="https://users.encs.concordia.ca/~abatmaz" rel="external nofollow noopener" target="_blank">Anil Ufuk Batmaz</a> </div> <div class="periodical"> <em>In Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</em>, Yokohama, Tokyo, Japan, May 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3706599.3719717" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/full/10.1145/3706599.3719717" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/Y_sm5XVLLDk" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1145/3706599.3719717" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=zDyfhn0AAAAJ&amp;citation_for_view=zDyfhn0AAAAJ:hqOjcs7Dif8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Due to the increasing availability and popularity of virtual reality (VR) systems, 3D sketching applications have also boomed. Most of these applications focus on peripersonal sketching, e.g., within arm’s reach. Yet, sketching in larger scenes requires users to walk around the virtual environment while sketching or to change the sketch scale repeatedly. This paper presents Depth3DSketch, a 3D sketching technique that allows users to sketch objects up to 2.5 m away with a freehand sketching technique. Users can select the sketching depth with three interaction methods: using the joystick on a single controller, the intersection from two controllers, or the intersection from the controller ray and the user’s gaze. We compared these interaction methods in a user study. Results show that users preferred the joystick to select visual depth, but there was no difference in user accuracy or sketching time between the three methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3706599.3719717</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bashar, Mohammad Raihanul and Amini, Mohammadreza and Stuerzlinger, Wolfgang and Sarac, Mine and Pfeuffer, Ken and Barrera Machuca, Mayra Donaji and Batmaz, Anil Ufuk}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Depth3DSketch: Freehand Sketching Out of Arm's Reach in Virtual Reality}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400713958}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3706599.3719717}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3706599.3719717}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{175}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{3D Sketching, Eye-Gaze, VR, 3D User Interface, Multimodal}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Yokohama, Tokyo, Japan}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI EA '25}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/With_Ball.gif" sizes="200px"> <img src="/assets/img/publication_preview/With_Ball.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="With_Ball.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="10918865" class="col-sm-8"> <div class="title">An Early Warning System Based on Visual Feedback for Light-Based Hand Tracking Failures in VR Head-Mounted Displays</div> <div class="author"> <em>Mohammad Raihanul Bashar</em>, and <a href="https://users.encs.concordia.ca/~abatmaz" rel="external nofollow noopener" target="_blank">Anil Ufuk Batmaz</a> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Saint-Malo, Brittany, France, Mar 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2025.3549544" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10918865/media#media" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/poVOJ4fRG58" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/TVCG.2025.3549544" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=zDyfhn0AAAAJ&amp;citation_for_view=zDyfhn0AAAAJ:UebtZRa9Y70C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>State-of-the-art Virtual Reality (VR) Head-Mounted Displays (HMDs) enable users to interact with virtual objects using their hands via built-in camera systems. However, the accuracy of the hand movement detection algorithm is often affected by limitations in both camera hardware and software, including image processing &amp; machine learning algorithms used for hand skeleton detection. In this work, we investigated a visual feedback mechanism to create an early warning system that detects hand skeleton recognition failures in VR HMDs and warns users in advance. We conducted two user studies to evaluate the system’s effectiveness. The first study involved a cup stacking task, where participants stacked virtual cups. In the second study, participants performed a ball sorting task, picking and placing colored balls into corresponding baskets. During both of the studies, we monitored the built-in hand tracking confidence of the VR HMD system and provided visual feedback to the user to warn them when the tracking confidence is ‘low’. The results showed that warning users before the hand tracking algorithm fails improved the system’s usability while reducing frustration. The impact of our results extends beyond VR HMDs, any system that uses hand tracking, such as robotics, can benefit from this approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10918865</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bashar, Mohammad Raihanul and Batmaz, Anil Ufuk}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Visualization and Computer Graphics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Early Warning System Based on Visual Feedback for Light-Based Hand Tracking Failures in VR Head-Mounted Displays}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Hands;Tracking;Visualization;Virtual environments;Cameras;Real-time systems;Usability;Alarm systems;Accuracy;User experience;Hand Tracking;Virtual Reality;Visual Feedback;System Usability;Early warning}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TVCG.2025.3549544}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1941-0506}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Saint-Malo, Brittany, France}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/GI_24-480.webp 480w,/assets/img/publication_preview/GI_24-800.webp 800w,/assets/img/publication_preview/GI_24-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/GI_24.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="GI_24.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="10.1145/3670947.3670983" class="col-sm-8"> <div class="title">Virtual Task Environments Factors Explored in 3D Selection Studies</div> <div class="author"> <em>Mohammad Raihanul Bashar</em>, and <a href="https://users.encs.concordia.ca/~abatmaz" rel="external nofollow noopener" target="_blank">Anil Ufuk Batmaz</a> </div> <div class="periodical"> <em>In Proceedings of the 50th Graphics Interface Conference</em>, Halifax, NS, Canada, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3670947.3670983" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/abs/10.1145/3670947.3670983" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://www.growkudos.com/publications/10.1145%252F3670947.3670983/reader" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1145/3670947.3670983" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=zDyfhn0AAAAJ&amp;citation_for_view=zDyfhn0AAAAJ:_FxGoFyzp5QC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In recent years, there has been a race among researchers, developers, engineers, and designers to come up with new interaction techniques for enhancing the performance and experience of users while interacting with virtual environments, and a key component of a 3D interaction technique is the selection technique. In this paper, we explore the environmental factors used in the assessment of 3D selection methods and classify each factor based on the task environment. Our approach consists of a thorough literature collection process, including four major Human-Computer Interaction repositories—Scopus, Science Direct, IEEE Xplore, and ACM Digital Library and created a dataset of a total of 277 papers. Drawing inspiration from the parameters outlined by LaViola et al. we manually classified each of those papers based on the task environment described in the papers. In addition, we explore the methodologies used in recent user studies to assess interaction techniques within various task environments, providing valuable insights into the developing landscape of virtual interaction research. We hope that the outcomes of our paper serve as a valuable resource for researchers, developers, and designers, providing a deeper understanding of task environments and offering fresh perspectives to evaluate their proposed 3D selection techniques in virtual environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3670947.3670983</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bashar, Mohammad Raihanul and Batmaz, Anil Ufuk}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Virtual Task Environments Factors Explored in 3D Selection Studies}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400718281}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3670947.3670983}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3670947.3670983}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 50th Graphics Interface Conference}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{3D Selection, 3D User Interfaces, Augmented Reality, Human-centered computing, Virtual Reality, Virtual Task Environment}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Halifax, NS, Canada}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{GI '24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/book-480.webp 480w,/assets/img/publication_preview/book-800.webp 800w,/assets/img/publication_preview/book-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/book.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="book.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="mutasim2018computational" class="col-sm-8"> <div class="title">Computational intelligence for pattern recognition in eeg signals</div> <div class="author"> <a href="https://scholar.google.com/citations?user=1Nt5UowAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Aunnoy K Mutasim</a>, Rayhan Sardar Tipu, <em>M Raihanul Bashar</em>, Md Kafiul Islam, and M Ashraful Amin </div> <div class="periodical"> Mar 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-319-89629-8_11" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-319-89629-8_11" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.growkudos.com/1q817cpb3ls" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-319-89629-8_11" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=zDyfhn0AAAAJ&amp;citation_for_view=zDyfhn0AAAAJ:LkGwnXOMwfcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-16-4285F4?logo=googlescholar&amp;labelColor=beige" alt="16 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Electroencephalography (EEG) captures brain signals from Scalp. If analyzed and patterns are recognized properly this has a high potential application in medicine, psychology, rehabilitation, and many other areas. However, EEG signals are inherently noise-prone, and it is not possible for human to see patterns in raw signals most of the time. Application of appropriate computational intelligence is must to make sense of the raw EEG signals. Moreover, if the signals are collected by a consumer grade wireless EEG acquisition device, the amount of interference is ever more complex to avoid, and it becomes impossible to see any sorts of pattern without proper use of computational intelligence to discover patterns. The objective of EEG based Brain-Computer Interface (BCI) systems is to extract specific signature of the brain activity and to translate them into command signals to control external devices or understand human brains action mechanism to stimuli. A typical BCI system is comprised of a Signal Processing module which can be further broken down into four submodules namely, Pre-processing, Feature Extraction, Feature Selection and Classification. Computational intelligence is the key to identify and extract features also to classify or discover discriminating characteristics in signals. In this chapter we present an overview how computational intelligence is used to discover patterns in brain signals. From our research we conclude that, since EEG signals are the outcome of a highly complex non-linear and non-stationary stochastic biological process which contain a wide variety of noises both from internal and external sources; thus, the use of computational intelligence is required at every step of an EEG-based BCI system starting from removing noises (using advanced signal processing techniques such as SWTSD, ICA, EMD, other than traditional filtering by identifying/exploiting different artifact/noise characteristics/patterns) through feature extraction and selection (by using unsupervised learning like PCA, SVD, etc.) and finally to classification (either supervised learning based classifier like SVM, probabilistic classifier like NB or unsupervised learning based classifiers like neural networks namely RBF, MLP, DBN, k-NN, etc.). And the usage of appropriate computational intelligence significantly improves the end results.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@book</span><span class="p">{</span><span class="nl">mutasim2018computational</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Computational intelligence for pattern recognition in eeg signals}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mutasim, Aunnoy K and Tipu, Rayhan Sardar and Bashar, M Raihanul and Islam, Md Kafiul and Amin, M Ashraful}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computational Intelligence for Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{291--320}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-89629-8_11}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Computational intelligence, Pattern recognition, EEG, BCI, SWT, SWTSD, PCA, LDA, SVD, Neural networks, Deep belief network, CNN, ERP, FFT, NB, Motor imagery, SVM, VCC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="https://dl.acm.org/profile/99661353918/" title="ACM DL" rel="external nofollow noopener" target="_blank"><i class="ai ai-acm"></i></a> <a href="mailto:%6D%6F%68%61%6D%6D%61%64%72%61%69%68%61%6E%75%6C.%62%61%73%68%61%72@%6D%61%69%6C.%63%6F%6E%63%6F%72%64%69%61.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://ieeexplore.ieee.org/author/37086184563/" title="IEEE Xplore" rel="external nofollow noopener" target="_blank"><i class="ai ai-ieee"></i></a> <a href="https://www.linkedin.com/in/mbraihan" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://orcid.org/0000-0002-5271-457X" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=zDyfhn0AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.scopus.com/authid/detail.uri?authorId=57213289907" title="Scopus" rel="external nofollow noopener" target="_blank"><i class="ai ai-scopus"></i></a> <a href="https://www.semanticscholar.org/author/2303687304" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://twitter.com/rbfahim" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Mohammad Raihanul Bashar. Last updated: July 04, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-RGT9JVC5K8"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-RGT9JVC5K8');
  </script> <script defer src="/assets/js/google-analytics-setup.js?12374742c4b1801ba82226e617af7e2d"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>