<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Mohammad Raihanul Bashar </title> <meta name="author" content="Mohammad Raihanul Bashar"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website, raihan, mohammad raihanul bashar"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?4ee140d0c7b1d5ca6cc5692caaf6bfdd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mbraihan.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Mohammad Raihanul</span> Bashar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/GI_24-480.webp 480w,/assets/img/publication_preview/GI_24-800.webp 800w,/assets/img/publication_preview/GI_24-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/GI_24.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="GI_24.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bashar2024virtual" class="col-sm-8"> <div class="title">Virtual Task Environments Factors Explored in 3D Selection Studies</div> <div class="author"> <em>Mohammad Raihanul Bashar</em>, and Anil Ufuk Batmaz </div> <div class="periodical"> <em>In Graphics Interface</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3670947.3670983" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/abs/10.1145/3670947.3670983" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://www.growkudos.com/publications/10.1145%252F3670947.3670983/reader" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="abstract hidden"> <p>In recent years, there has been a race among researchers, developers, engineers, and designers to come up with new interaction techniques for enhancing the performance and experience of users while interacting with virtual environments, and a key component of a 3D interaction technique is the selection technique. In this paper, we explore the environmental factors used in the assessment of 3D selection methods and classify each factor based on the task environment. Our approach consists of a thorough literature collection process, including four major Human-Computer Interaction repositories—Scopus, Science Direct, IEEE Xplore, and ACM Digital Library and created a dataset of a total of 277 papers. Drawing inspiration from the parameters outlined by LaViola et al. we manually classified each of those papers based on the task environment described in the papers. In addition, we explore the methodologies used in recent user studies to assess interaction techniques within various task environments, providing valuable insights into the developing landscape of virtual interaction research. We hope that the outcomes of our paper serve as a valuable resource for researchers, developers, and designers, providing a deeper understanding of task environments and offering fresh perspectives to evaluate their proposed 3D selection techniques in virtual environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bashar2024virtual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Virtual Task Environments Factors Explored in 3D Selection Studies}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bashar, Mohammad Raihanul and Batmaz, Anil Ufuk}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Graphics Interface}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--16}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3670947.3670983}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Human-centered computing, Virtual Reality, Augmented Reality, 3D User Interfaces, 3D Selection, Virtual Task Environment}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/NIDIT_2024-480.webp 480w,/assets/img/publication_preview/NIDIT_2024-800.webp 800w,/assets/img/publication_preview/NIDIT_2024-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/NIDIT_2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="NIDIT_2024.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="voisard2024subtask" class="col-sm-8"> <div class="title">Subtask-Based Virtual Hand Visualization Method for Enhanced User Accuracy in Virtual Reality Environments</div> <div class="author"> Laurent Voisard, Amal Hatira, <em>Mohammad Raihanul Bashar</em>, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Mucahit Gemici, Mine Sarac, Marta Kereten-Oertel, Anil Ufuk Batmaz' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In 2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VRW62533.2024.00008" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10536569" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.growkudos.com/1q5ksjiyry8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="abstract hidden"> <p>In the virtual hand interaction techniques, the opacity of the virtual hand avatar can potentially obstruct users’ visual feedback, leading to detrimental effects on accuracy and cognitive load. Given that the cognitive load is related to gaze movements, our study focuses on analyzing the gaze movements of participants across opaque, transparent, and invisible hand visualizations in order to create a new interaction technique. For our experimental setup, we used a Purdue Pegboard Test with reaching, grasping, transporting, and inserting subtasks. We examined how long and where participants concentrated on these subtasks and, using the findings, introduced a new virtual hand visualization method to increase accuracy. We hope that our results can be used in future virtual reality applications where users have to interact with virtual objects accurately.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">voisard2024subtask</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Subtask-Based Virtual Hand Visualization Method for Enhanced User Accuracy in Virtual Reality Environments}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Voisard, Laurent and Hatira, Amal and Bashar, Mohammad Raihanul and Gemici, Mucahit and Sarac, Mine and Kereten-Oertel, Marta and Batmaz, Anil Ufuk}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6--11}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/VRW62533.2024.00008}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Human-centered computing, Visualization, Visualization techniques, Visualization design and evaluation methods}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/neuro-480.webp 480w,/assets/img/publication_preview/neuro-800.webp 800w,/assets/img/publication_preview/neuro-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/neuro.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="neuro.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sourov2023eeg" class="col-sm-8"> <div class="title">EEG-Based Preference Classification for Neuromarketing Application</div> <div class="author"> Injamamul Haque Sourov, Faiyaz Alvi Ahmed, Md Tawhid Islam Opu, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Aunnoy K Mutasim, M Raihanul Bashar, Rayhan Sardar Tipu, Md Ashraful Amin, Md Kafiul Islam' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Computational Intelligence and Neuroscience</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1155/2023/4994751" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://onlinelibrary.wiley.com/doi/10.1155/2023/4994751" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.growkudos.com/1pzxryi6yv4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="abstract hidden"> <p>Neuromarketing is a modern marketing research technique whereby consumers’ behavior is analyzed using neuroscientific approaches. In this work, an EEG database of consumers’ responses to image advertisements was created, processed, and studied with the goal of building predictive models that can classify the consumers’ preference based on their EEG data. Several types of analysis were performed using three classifier algorithms, namely, SVM, KNN, and NN pattern recognition. The maximum accuracy and sensitivity values are reported to be 75.7% and 95.8%, respectively, for the female subjects and the KNN classifier. In addition, the frontal region electrodes yielded the best selective channel performance. Finally, conforming to the obtained results, the KNN classifier is deemed best for preference classification problems. The newly created dataset and the results derived from it will help research communities conduct further studies in neuromarketing.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sourov2023eeg</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{EEG-Based Preference Classification for Neuromarketing Application}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sourov, Injamamul Haque and Ahmed, Faiyaz Alvi and Opu, Md Tawhid Islam and Mutasim, Aunnoy K and Bashar, M Raihanul and Tipu, Rayhan Sardar and Amin, Md Ashraful and Islam, Md Kafiul}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computational Intelligence and Neuroscience}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4994751}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1155/2023/4994751}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Wiley Online Library}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eyeblink-480.webp 480w,/assets/img/publication_preview/eyeblink-800.webp 800w,/assets/img/publication_preview/eyeblink-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/eyeblink.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eyeblink.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="jalilifard2020use" class="col-sm-8"> <div class="title">Use of spontaneous blinking for application in human authentication</div> <div class="author"> Amir Jalilifard, Dehua Chen, Aunnoy K Mutasim, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'M Raihanul Bashar, Rayhan Sardar Tipu, Ahsan-Ul Kabir Shawon, Nazmus Sakib, M Ashraful Amin, Md Kafiul Islam' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>Engineering Science and Technology, an International Journal</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.jestch.2020.05.007" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S221509861931403X#:%C2%A0:text=Our%20results%20show%20that%20individuals,sequence%20of%20involuntary%20blinking%20signals." class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.growkudos.com/1ne2joxjx8g" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="abstract hidden"> <p>Contamination of electroencephalogram (EEG) signals due to natural blinking electrooculogram (EOG) signals is often removed to enhance the quality of EEG signals. This paper discusses the possibility of using solely involuntary blinking signals for human authentication. The EEG data of 46 subjects were recorded while the subject was looking at a sequence of different pictures. During the experiment, the subject was not focused on any kind of blinking task. Having the blink EOG signals separated from EEG, 25 features were extracted and the data were preprocessed in order to handle the corrupt or missing values. Since spontaneous and voluntary blinks have different characteristics in terms of kinematic variables and because the previous studies’ control setup may have altered the type of blink from spontaneous to voluntary, a series of statistical analysis was carried out in order to inspect the changes in the multivariate probability distribution of data compared to the previous studies. Statistical significance shows that it is very likely that the blink features of both voluntary and involuntary blink signal are generated by Gaussian probability density function, although different than voluntary blink, spontaneous blink is not well discriminated with Gaussian. Despite testing several models, none managed to classify the data using only the information of a single spontaneous blink. Thereby, we examined the possibility of learning the patterns of a series of blinks using Gated Recurrent Unit (GRU). Our results show that individuals can be distinguished with up to 98.7% accuracy using only a reasonably short sequence of involuntary blinking signals.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">jalilifard2020use</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Use of spontaneous blinking for application in human authentication}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jalilifard, Amir and Chen, Dehua and Mutasim, Aunnoy K and Bashar, M Raihanul and Tipu, Rayhan Sardar and Shawon, Ahsan-Ul Kabir and Sakib, Nazmus and Amin, M Ashraful and Islam, Md Kafiul}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Engineering Science and Technology, an International Journal}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{23}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{903--910}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.jestch.2020.05.007}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{User authentication, Eye blinking, Biometric, Electro-encephalogram, Electro-oculogram, Recurrent Neural Network, RNN, EEG, GRU, EOG}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/EMG-480.webp 480w,/assets/img/publication_preview/EMG-800.webp 800w,/assets/img/publication_preview/EMG-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/EMG.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="EMG.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mutasim2018effect" class="col-sm-8"> <div class="title">Effect of Artefact Removal Techniques on EEG Signals for Video Category Classification</div> <div class="author"> Aunnoy K Mutasim, M Raihanul Bashar, Rayhan Sardar Tipu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Md Kafiul Islam, M Ashraful Amin' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In 2018 24th International Conference on Pattern Recognition (ICPR)</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ICPR.2018.8545416" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8545416&amp;casa_token=6-ikHHVmK2YAAAAA:_5C9f6Q-4tGKEyS-s-tEKs29CuY-APgvnzkt-YFggKjoSPrkw-PNfyadxASVMsoNLEorWlP1xn4&amp;tag=1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.growkudos.com/1hvm2ewh91c" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="abstract hidden"> <p>Pre-processing, Feature Extraction, Feature Selection and Classification are the four sub modules of the Signal Processing module of a typical BCI system. Pattern recognition is mainly involved in this Signal Processing module and in this paper, we experimented with different state-of-the-art algorithms for each of these submodules on two separate datasets we acquired using Emotiv EPOC and the Muse headband from 38 college-aged young adults. For our experiment, we used two artefact removal techniques, namely Stationary Wavelet Transform (SWT) based denoising technique and an extended SWT technique (SWTSD). We found SWTSD improves average classification accuracy up to 7.2 % and performs better than SWT. However, that does not state that SWTSD will outperform SWT when implemented on other BCI paradigms or on other EEG-based applications. In our study, the highest average accuracy achieved by the data of the Muse headband and Emotiv EPOC were 77.7% and 66.7% respectively and from our results we conclude that, the performance of different BCI systems depends on several different factors including artefact removal techniques, filters, feature extraction and selection algorithms, classifiers, etc. and appropriate choice and usage of such methods can have a significant positive impact on the end results.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mutasim2018effect</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Effect of Artefact Removal Techniques on EEG Signals for Video Category Classification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mutasim, Aunnoy K and Bashar, M Raihanul and Tipu, Rayhan Sardar and Islam, Md Kafiul and Amin, M Ashraful}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2018 24th International Conference on Pattern Recognition (ICPR)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3513--3518}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICPR.2018.8545416}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Brain-Computer Interface, BCI, EEG, Video Category Classification, VCC, SVM, SWT, SWTSD}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/book-480.webp 480w,/assets/img/publication_preview/book-800.webp 800w,/assets/img/publication_preview/book-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/book.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="book.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mutasim2018computational" class="col-sm-8"> <div class="title">Computational intelligence for pattern recognition in eeg signals</div> <div class="author"> Aunnoy K Mutasim, Rayhan Sardar Tipu, M Raihanul Bashar, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Md Kafiul Islam, M Ashraful Amin' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Computational Intelligence for Pattern Recognition</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-319-89629-8_11" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-319-89629-8_11" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.growkudos.com/1q817cpb3ls" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="abstract hidden"> <p>Electroencephalography (EEG) captures brain signals from Scalp. If analyzed and patterns are recognized properly this has a high potential application in medicine, psychology, rehabilitation, and many other areas. However, EEG signals are inherently noise-prone, and it is not possible for human to see patterns in raw signals most of the time. Application of appropriate computational intelligence is must to make sense of the raw EEG signals. Moreover, if the signals are collected by a consumer grade wireless EEG acquisition device, the amount of interference is ever more complex to avoid, and it becomes impossible to see any sorts of pattern without proper use of computational intelligence to discover patterns. The objective of EEG based Brain-Computer Interface (BCI) systems is to extract specific signature of the brain activity and to translate them into command signals to control external devices or understand human brains action mechanism to stimuli. A typical BCI system is comprised of a Signal Processing module which can be further broken down into four submodules namely, Pre-processing, Feature Extraction, Feature Selection and Classification. Computational intelligence is the key to identify and extract features also to classify or discover discriminating characteristics in signals. In this chapter we present an overview how computational intelligence is used to discover patterns in brain signals. From our research we conclude that, since EEG signals are the outcome of a highly complex non-linear and non-stationary stochastic biological process which contain a wide variety of noises both from internal and external sources; thus, the use of computational intelligence is required at every step of an EEG-based BCI system starting from removing noises (using advanced signal processing techniques such as SWTSD, ICA, EMD, other than traditional filtering by identifying/exploiting different artifact/noise characteristics/patterns) through feature extraction and selection (by using unsupervised learning like PCA, SVD, etc.) and finally to classification (either supervised learning based classifier like SVM, probabilistic classifier like NB or unsupervised learning based classifiers like neural networks namely RBF, MLP, DBN, k-NN, etc.). And the usage of appropriate computational intelligence significantly improves the end results.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">mutasim2018computational</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Computational intelligence for pattern recognition in eeg signals}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mutasim, Aunnoy K and Tipu, Rayhan Sardar and Bashar, M Raihanul and Islam, Md Kafiul and Amin, M Ashraful}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computational Intelligence for Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{291--320}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-89629-8_11}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Computational intelligence, Pattern recognition, EEG, BCI, SWT, SWTSD, PCA, LDA, SVD, Neural networks, Deep belief network, CNN, ERP, FFT, NB, Motor imagery, SVM, VCC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/stereo-480.webp 480w,/assets/img/publication_preview/stereo-800.webp 800w,/assets/img/publication_preview/stereo-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/stereo.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="stereo.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bashar20172d" class="col-sm-8"> <div class="title">2D surface mapping for mine detection using wireless network</div> <div class="author"> M Raihanul Bashar, Abul Al Arabi, Rayhan Sardar Tipu, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'M Tanvir Alam Sifat, M Zobair Ibn Alam, M Ashraful Amin' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In 2017 2nd International Conference on Control and Robotics Engineering (ICCRE)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ICCRE.2017.7935066" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/8424311" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.growkudos.com/1e9hifaja4g" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="abstract hidden"> <p>There are presently approximately 500 million live, buried mines in about 70 countries, which present a major threat to lives and cause economic problems. It is a matter of deep concern because it’s difficult to detect the mines when their exact position is unknown. Though governments of affected countries take this matters seriously, there is no significant progress as they are still practicing manual methods from decades ago. It would take almost hundreds of years if we kept relying on those manual methods because of wide variety of mines with tremendous diversity of terrains. The purpose of this paper is to design a mapping robot system prototype (MinerBot) using microcontroller and sensors which is capable of mapping any surface with depth value in real time which will then help in mine detection. MinerBot can move in any direction and collect information using ultrasonic sensor, which is connected to a microcontroller then it was passed on to the mapping function in MATLAB via socket communication. MinerBot is autonomous, efficient and cheap.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bashar20172d</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{2D surface mapping for mine detection using wireless network}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bashar, M Raihanul and Al Arabi, Abul and Tipu, Rayhan Sardar and Sifat, M Tanvir Alam and Alam, M Zobair Ibn and Amin, M Ashraful}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2017 2nd International Conference on Control and Robotics Engineering (ICCRE)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{180--183}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICCRE.2017.7935066}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Stereo Vision, Movable multi-cameras, distance measurement, robotic vision, image processing, humanoid vision, self calibration}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="bashar2017effect" class="col-sm-8"> <div class="title">Effect of EMG artifacts on video category classification from EEG</div> <div class="author"> <em>Mohammad Raihanul Bashar</em>, Rayhan Sardar Tipu, Aunnoy K Mutasim, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'M Ashraful Amin' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In 2017 6th International Conference on Informatics, Electronics and Vision &amp; 2017 7th International Symposium in Computational Medical and Health Technology (ICIEV-ISCMHT)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ICIEV.2017.8338603" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/8338603" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.growkudos.com/1pqwo896mf4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="abstract hidden"> <p>EEG (electroencephalography) signals are highly susceptible to noise. Mixture of artifacts like EOG (electrooculography) and EMG (electromyography) with the EEG signals are inevitable. In this paper, we present our findings of the effects of EMG artifacts on EEG signals to categorize videos. The experiments suggest that for video category classification using EEG, signals with EMG artifacts have more discriminating capacity.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bashar2017effect</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Effect of EMG artifacts on video category classification from EEG}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bashar, Mohammad Raihanul and Tipu, Rayhan Sardar and Mutasim, Aunnoy K and Amin, M Ashraful}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2017 6th International Conference on Informatics, Electronics and Vision \&amp; 2017 7th International Symposium in Computational Medical and Health Technology (ICIEV-ISCMHT)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--4}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICIEV.2017.8338603}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{EEG, EMG, BCI, HCI, Multimedia Classification}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="al2017implementation" class="col-sm-8"> <div class="title">Implementation of Low Cost Stereo Humanoid Adaptive Vision for 3D Positioning and Distance Measurement for Robotics Application with Self-Calibration</div> <div class="author"> Abul Al Arabi, Rayhan Sardar Tipu, <em>Mohammad Raihanul Bashar</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Binoy Barman, Shama Ali Monicay, Md Ashraful Amin' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In 2017 Asia Modelling Symposium (AMS)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/AMS.2017.21" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/7935066" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.growkudos.com/1bg537vev40" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> </div> <div class="abstract hidden"> <p>Robots are getting smarter everyday with the implementation of computer vision system in it. It is now highly required for any robot to have a natural vision system or more likely humanoid vision system to interact with real life incidents. On the perspective of such imaging and vision, we propose an efficient method in order to determine the absolute view point of any desired image location. We used self calibration system and humanoid vision mechanism via stereo cameras to find the region of convergent of an object which with the help of a mathematical model can measure the distance of the object. With comparing different objects position it is also possible to determine the relative distance of the objects. Our system shows that, the real human eye tracking system used, can be possible for getting a realistic view of the image at the 3D point positioning.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">al2017implementation</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Implementation of Low Cost Stereo Humanoid Adaptive Vision for 3D Positioning and Distance Measurement for Robotics Application with Self-Calibration}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Al Arabi, Abul and Tipu, Rayhan Sardar and Bashar, Mohammad Raihanul and Barman, Binoy and Monicay, Shama Ali and Amin, Md Ashraful}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2017 Asia Modelling Symposium (AMS)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{83--88}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/AMS.2017.21}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Microcontroller based Robot, Multi-sensor devices, Metal Detection Sensor, MATLAB, Surface Mapping, 2D mapping, Mine detection}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Mohammad Raihanul Bashar. # Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. # Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>